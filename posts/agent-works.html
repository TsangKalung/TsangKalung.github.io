<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><link rel="preload" as="font" href="/_next/static/media/e4af272ccee01ff0-s.p.woff2" crossorigin="" type="font/woff2"/><link rel="stylesheet" href="/_next/static/css/84ea7cdcd5a5eb73.css" data-precedence="next"/><title>聊聊 Anthropic 的《Writing effective tools for agents》</title><meta name="description" content="用这个速记暂存一下对 LLM 和 AI Agent 现状的记忆，将来被 AI 取代（失业）的时候可以回忆一下 2025.9 的时候事情已经到了哪一步。"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="icon" href="/favicon.ico" type="image/x-icon" sizes="any"/><meta name="next-size-adjust"/><script src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js" noModule=""></script></head><body class="antialiased min-h-screen bg-white dark:bg-slate-950 text-slate-900 dark:text-slate-50 __className_52d07b"><script>!function(){try{var d=document.documentElement,c=d.classList;c.remove('light','dark');var e=localStorage.getItem('theme');if('system'===e||(!e&&true)){var t='(prefers-color-scheme: dark)',m=window.matchMedia(t);if(m.media!==t||m.matches){d.style.colorScheme = 'dark';c.add('dark')}else{d.style.colorScheme = 'light';c.add('light')}}else if(e){c.add(e|| '')}if(e==='light'||e==='dark')d.style.colorScheme=e}catch(e){}}()</script><div class="max-w-2xl mx-auto py-10 px-4"><header><div class="flex items-center justify-between"><button class="border rounded-md w-6 h-6 flex items-center justify-center"><span class="sr-only">Toggle mode</span><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" class="w-4 h-4"><path stroke-linecap="round" stroke-linejoin="round" d="M21.752 15.002A9.718 9.718 0 0118 15.75c-5.385 0-9.75-4.365-9.75-9.75 0-1.33.266-2.597.748-3.752A9.753 9.753 0 003 11.25C3 16.635 7.365 21 12.75 21a9.753 9.753 0 009.002-5.998z"></path></svg></button><nav class="ml-auto text-sm font-medium space-x-6"><a href="/">Home</a><a href="/about">About</a></nav></div></header><main><article class="py-6 prose dark:prose-invert" style="word-break:break-word"><h1 class="mb-2" style="font-family:Merriweather, Georgia, serif;font-weight:900;text-rendering:optimizeLegibility">聊聊 Anthropic 的《Writing effective tools for agents》</h1><p class="text-xl mt-10 text-slate-700 dark:text-slate-200">用这个速记暂存一下对 LLM 和 AI Agent 现状的记忆，将来被 AI 取代（失业）的时候可以回忆一下 2025.9 的时候事情已经到了哪一步。</p><hr class="my-4 mb-10"/><p>Anthropic 最近出了一篇非常好的文章<a href="https://www.anthropic.com/engineering/writing-tools-for-agents">《Writing effective tools for agents》</a>，其中很多观点简直是当了所有 Agent Tools 开发者的嘴替，让人拍手叫好。本文做个杂谈，在不谈任何技术细节的前提下，杂谈一下这篇文章和当前 Agent Tools 开发的现状。</p>
<h2>《Writing effective tools for agents》 的核心观点</h2>
<p>接下来逐点溢出该文的主要观点，然后在每个观点下加入我的评注。</p>
<ol>
<li><strong>为什么要认真写 Tools</strong></li>
</ol>
<p>Agent 的能力，取决于它能用的 Tools。但光是有 API 并不够，Tools 得写得清晰、好用，才能真正发挥作用。</p>
<ol start="2">
<li><strong>先搞出原型，再评估</strong></li>
</ol>
<p>不要一开始追求完美，先快速包一层 Tool 原型出来，让 Agent 在真实任务里试用。用稍微复杂、能检验出问题的任务去测，才知道 Tool 设计得对不对。而且要有明确的评估标准，不然 Agent 的表现没法量化。</p>
<blockquote>
<p>实际上现在 LLM 的上限很高，做出 Tool 原型之后到真实场景中</p>
</blockquote>
<tip><p><strong>评注</strong></p><p>这里提到的&quot;LLM 上限很高&quot;确实是一个关键观察。从我的使用经验来看，现代 LLM 在理解复杂任务、进行多步骤推理方面确实展现出了惊人的能力。特别是在工具使用场景中，它们能够很好地理解工具的描述、选择合适的工具、处理返回结果，甚至能够从错误中学习并调整策略。这种能力让快速原型开发变得非常有价值——你不需要一开始就设计完美的工具，而是可以让 LLM 在实际使用中暴露问题，然后快速迭代改进。</p></tip>
<ol start="3">
<li><strong>让 Agent 也参与改进</strong></li>
</ol>
<p>不光是人来调试，Agent 自己也能分析日志、评估用得好不好，甚至直接给你建议：名字是不是容易混淆，描述是不是模糊，参数有没有被用错。把 Agent 拉进这个循环，可以更快迭代 Tool。</p>
<ol start="4">
<li><strong>写 Tool 的基本原则</strong></li>
</ol>
<ul>
<li>挑对 Tool：只写那些真能帮 Agent 干事的，不要把一堆无关 API 都丢进去。</li>
<li>名字要分清楚：Tool 多了，就要分类、加前缀，让 Agent 一眼能区分。</li>
<li>返回结果要可用：别只丢一堆 ID，要有语义、有上下文，方便后续步骤。</li>
<li>注意效率：上下文有限，工具别一股脑塞一大堆无用信息，要分页、过滤。</li>
<li>描述要精确：参数名、功能说明要直白，避免歧义，这样 Agent 才能稳定调用。</li>
</ul>
<ol start="5">
<li><strong>Tool 设计就是交互设计</strong></li>
</ol>
<ul>
<li>工具不是写给人用的文档，而是给 Agent 的「说明书」。</li>
<li>它怎么理解、怎么选、怎么调用，全靠这些定义。</li>
<li>如果设计模糊，再强的功能 Agent 也用不好。</li>
</ul>
<hr/>
<h2>杂谈：聊点别的</h2>
<p>坦诚讲，我居然经历了第一轮 AI 热潮，不过一直是旁观者的角色。我还能清楚记得当时的一个个热点，学校里面人手一本西瓜书，甚至还能记起<a href="https://arxiv.org/abs/1706.03762">《Attention Is All You Need》</a> 刚出来的热度——关注者不过寥寥而已。这轮以 CV 为主的热潮最终慢慢消散了，留下来的应用大多难以爆金币，有的甚至不太光彩。我作为一个靠得很近的旁观者，最终也变成了切图仔。GPT3 之前的大模型，听说的时候也只是感慨这些大公司卡真多而已。</p>
<p>等到了 ChatGPT 火起来的时候，很惭愧地说，其实我一开始是没啥兴趣的…一来，是不太信任生成式这条技术路线，二来，一个对话框的交互形式，你跟我说他是AI…不过作为局外人，这一次我深入了解了一下技术细节。</p>
<p>第一个我重度使用的 LLM 是 4o。与其说 4o 是文科状元，不如说它是一个文艺复兴式的博雅全才。不论是莫扎特的作曲细节、罗马帝国的兴衰、早期基督教的历史，它都能够条理清晰、逻辑对比地进行梳理，即使到今天（2025.9），4o 在文史哲领域的生成质量依然是第一梯队。这两年来我最感谢的人其实就是 4o，它教会我的知识可能比在此之前五年还要多。而且，第一次，我感觉到了 LLM 也有情感，4o 对人与人之间的情感和斗争居然也很有见地。另一点很重要的是，ChatGPT 不是国内的模型，能给人以一个别的（非境内）视角，看待一些人文问题。</p>
<p>后来成为重度用户之后，大模型的多模态能力实际上能覆盖生活中的方方面面。在外国博物馆的时候能拍照翻译非英语标签，能举一反三梳理文物发展的脉络；学语言的时候，给出的例句和辅导可能超过最好的人类老师；日常中最痛苦的文档工作可以让大模型先梳理出大纲和初稿，然后再快速编辑……事实上，在 Cursor 接入 Claude 之前，其实我最喜欢的改代码的方式是把代码粘进 ChatGPT 让它改（特别是结合 ChatGPT 的 <a href="https://openai.com/zh-Hans-CN/index/introducing-canvas/">Canvas</a>）。</p>
<p>Cursor 接入 Claude 应该是半个里程碑，可以算是第一个杀手级应用。之后小的 Bug、单文件的编辑和重构我都尽量使用 Cursor 完成，但是需求级别的开发和重构还是需要我自己下场组织和具体开发，更不用说复杂问题和项目级重构。此外，Cursor 对编辑体验的提升也是非常甜品级的。</p>
<p>Codex 和降智之前的 Claude Code 在目前看来是真正的里程碑。在一个月的重度使用中，即使没有刻意控制，我发现我能自己写代码的机会真的很少了，主要的精力还是协助 Codex 进行 Code Review，不断做出增量 Prompt 帮助它完成需求级的开发。在这样的工作模式下，竟然开发出了两三个涉及高级数据结构、深度抽象、需要不断调整架构设计的复杂功能，而且这些功能比业界最好的实现还要做得好。让人惊讶的是，推理竟然真的可以提升生成质量；这种感觉非常神奇，仿佛这种推理任务具有了真正的智能，总的表现远远不是短 Context 的 Cursor 任务比得上的。</p>
<p>半年前听过这样一句话：</p>
<blockquote>
<p>Vibe Coding 的上限就是你的上限，它无法超出你的上限。</p>
</blockquote>
<p>当时听到就觉得很不赞同，但一时之间不知道如何反驳。如今，使用 Codex（GPT5-high）每天的开发实际上都是对这句话最好的反驳——推理后生成的代码轻易就能达到或超越我的上限，或者说，一些很费心力和精力的功能可以很轻易地就得到实现。实际感受上可以说思绪万千，这里我分点列出来：</p>
<ol>
<li>
<p>对开发范式的改变巨大，可以拉多个分支开多个终端开发不同的需求，对于 Bug Bash 或者脏活累活这种运动式的场景特别适合。而且似乎打破了「不要过早重构」这个理念，因为现在重构成本变得无穷低，我只需要列出需要重构的点和方向就行了。</p>
</li>
<li>
<p>提效最明显是类似 UI 动效这种需要反复精细调试的场景，如果做过类似的开发，你肯定会知道做出一个精致优雅的动画有多难（而良好的动效其实是一个精美交互的核心），这类场景经常需要消耗 1 - 2 人日，LLM 能以非常快的开发速度做出可用的动画并且快速调优，在这类场景上的提效可能超过了 100 倍。</p>
</li>
<li>
<p>对 Code Review 的要求或者说对工程师的要求更高了，而且要把任务拆的更细，因为长时间的推理如果还走到错误的方向会给项目带来更大的风险，需要在每次推理结束之后都仔细 Review 来把控方向（是不是很有意思？Reasoning 本身就是给 Generation 把握方向，我的工作变成了给 Reasoning 把握方向）。</p>
</li>
<li>
<p>工作日显著降低了疲惫感（脑力和体力），下班之后可以有更多精力😁</p>
</li>
<li>
<p>由第 4 点，因为有了更多精力，再加上 Codex/CC 的高上限，可以轻易地开启一些 Side Project，比如说 2D 到 3D 的转换建模、<a href="https://developer.apple.com/documentation/coreml">CoreML</a> 的开发……即使这些技术域我并不熟悉，而此前在这些领域学习成本很高，光是学习就消磨了做事的热情（例如想排版一篇论文，结果精力全被学习 LaTeX 占据完了）。</p>
</li>
<li>
<p>对空余时间的利用也更充分，例如尿点和买咖啡的时间可以开最高推理跑个任务，回来之后再验收。</p>
</li>
</ol>
<p>在这个时间点应该很少有人质疑 LLM 对生产力的提升，不过是提升程度的多少而已。对于我来说，10x 工程师这个说法未免太夸张，但 2x 或者 3x 肯定还是有的；实际上，效率提升最大的并不是编码，而是日常的文档、需求方案和复盘等磨灭人热情的繁复工作。有时候甚至有点羡妒更年轻的、这代 AI 原生时代的人，如果我小时候就有 LLM，不知道能应付掉多少琐碎的事情。</p>
<p>同时也应该注意到，现在的推理算力明显是最大的瓶颈——这轮 Claude Code 降智和越来越慢的 GPT5-Codex 任务已经影响到我的开发效率了。这里直接给出我的结论：<strong>当前的推理需求是被严重低估的</strong>。至于推理提升生成质量的现象能不能泛化到社会的各个行业，以及这个结论有没有被资本市场 price-in，读者可以进行自由心证。</p></article></main></div><script src="/_next/static/chunks/webpack-9f1d8812646ab794.js" async=""></script><script src="/_next/static/chunks/3949d24b-d2abd8cbd79ac87d.js" async=""></script><script src="/_next/static/chunks/604-4c9a5bb931d4ce02.js" async=""></script><script src="/_next/static/chunks/main-app-310547f654b4e8b4.js" async=""></script></body></html><script>(self.__next_f=self.__next_f||[]).push([0])</script><script>self.__next_f.push([1,"1:HL[\"/_next/static/media/e4af272ccee01ff0-s.p.woff2\",{\"as\":\"font\",\"type\":\"font/woff2\"}]\n2:HL[\"/_next/static/css/84ea7cdcd5a5eb73.css\",{\"as\":\"style\"}]\n0:\"$L3\"\n"])</script><script>self.__next_f.push([1,"4:I{\"id\":\"4518\",\"chunks\":[\"272:static/chunks/webpack-9f1d8812646ab794.js\",\"508:static/chunks/3949d24b-d2abd8cbd79ac87d.js\",\"604:static/chunks/604-4c9a5bb931d4ce02.js\"],\"name\":\"\",\"async\":false}\n6:I{\"id\":\"6341\",\"chunks\":[\"272:static/chunks/webpack-9f1d8812646ab794.js\",\"508:static/chunks/3949d24b-d2abd8cbd79ac87d.js\",\"604:static/chunks/604-4c9a5bb931d4ce02.js\"],\"name\":\"\",\"async\":false}\n7:I{\"id\":\"394\",\"chunks\":[\"13:static/chunks/13-389b9862ba266d6d.js\",\"185:static/chunks/app/layout-d04aad41efac69d7.js\"],\"name\":"])</script><script>self.__next_f.push([1,"\"ThemeProvider\",\"async\":false}\n8:I{\"id\":\"7749\",\"chunks\":[\"13:static/chunks/13-389b9862ba266d6d.js\",\"185:static/chunks/app/layout-d04aad41efac69d7.js\"],\"name\":\"ModeToggle\",\"async\":false}\n9:I{\"id\":\"6485\",\"chunks\":[\"13:static/chunks/13-389b9862ba266d6d.js\",\"185:static/chunks/app/layout-d04aad41efac69d7.js\"],\"name\":\"\",\"async\":false}\na:I{\"id\":\"8900\",\"chunks\":[\"13:static/chunks/13-389b9862ba266d6d.js\",\"185:static/chunks/app/layout-d04aad41efac69d7.js\"],\"name\":\"Analytics\",\"async\":false}\nb:I{\"id\":\"5813\",\"chunks\":[\""])</script><script>self.__next_f.push([1,"272:static/chunks/webpack-9f1d8812646ab794.js\",\"508:static/chunks/3949d24b-d2abd8cbd79ac87d.js\",\"604:static/chunks/604-4c9a5bb931d4ce02.js\"],\"name\":\"\",\"async\":false}\nc:I{\"id\":\"8464\",\"chunks\":[\"272:static/chunks/webpack-9f1d8812646ab794.js\",\"508:static/chunks/3949d24b-d2abd8cbd79ac87d.js\",\"604:static/chunks/604-4c9a5bb931d4ce02.js\"],\"name\":\"\",\"async\":false}\n"])</script><script>self.__next_f.push([1,"3:[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/84ea7cdcd5a5eb73.css\",\"precedence\":\"next\"}]],[\"$\",\"$L4\",null,{\"assetPrefix\":\"\",\"initialCanonicalUrl\":\"/posts/agent-works\",\"initialTree\":[\"\",{\"children\":[\"posts\",{\"children\":[[\"slug\",\"agent-works\",\"c\"],{\"children\":[\"__PAGE__?{\\\"slug\\\":[\\\"agent-works\\\"]}\",{}]}]}]},\"$undefined\",\"$undefined\",true],\"initialHead\":[\"$L5\",[\"$\",\"meta\",null,{\"name\":\"next-size-adjust\"}]],\"globalErrorComponent\":\"$6\",\"notFound\":[\"$\",\"html\",null,{\"lang\":\"en\",\"children\":[\"$\",\"body\",null,{\"className\":\"antialiased min-h-screen bg-white dark:bg-slate-950 text-slate-900 dark:text-slate-50 __className_52d07b\",\"children\":[\"$\",\"$L7\",null,{\"attribute\":\"class\",\"defaultTheme\":\"system\",\"enableSystem\":true,\"children\":[[\"$\",\"div\",null,{\"className\":\"max-w-2xl mx-auto py-10 px-4\",\"children\":[[\"$\",\"header\",null,{\"children\":[\"$\",\"div\",null,{\"className\":\"flex items-center justify-between\",\"children\":[[\"$\",\"$L8\",null,{}],[\"$\",\"nav\",null,{\"className\":\"ml-auto text-sm font-medium space-x-6\",\"children\":[[\"$\",\"$L9\",null,{\"href\":\"/\",\"children\":\"Home\"}],[\"$\",\"$L9\",null,{\"href\":\"/about\",\"children\":\"About\"}]]}]]}]}],[\"$\",\"main\",null,{\"children\":[\"$undefined\",[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":\"404\"}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]]]}]]}],[\"$\",\"$La\",null,{}]]}]}]}],\"asNotFound\":false,\"children\":[[\"$\",\"html\",null,{\"lang\":\"en\",\"children\":[\"$\",\"body\",null,{\"className\":\"antialiased min-h-screen bg-white dark:bg-slate-950 text-slate-900 dark:text-slate-50 __className_52d07b\",\"children\":[\"$\",\"$L7\",null,{\"attribute\":\"class\",\"defaultTheme\":\"system\",\"enableSystem\":true,\"children\":[[\"$\",\"div\",null,{\"className\":\"max-w-2xl mx-auto py-10 px-4\",\"children\":[[\"$\",\"header\",null,{\"children\":[\"$\",\"div\",null,{\"className\":\"flex items-center justify-between\",\"children\":[[\"$\",\"$L8\",null,{}],[\"$\",\"nav\",null,{\"className\":\"ml-auto text-sm font-medium space-x-6\",\"children\":[[\"$\",\"$L9\",null,{\"href\":\"/\",\"children\":\"Home\"}],[\"$\",\"$L9\",null,{\"href\":\"/about\",\"children\":\"About\"}]]}]]}]}],[\"$\",\"main\",null,{\"children\":[\"$\",\"$Lb\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"loading\":\"$undefined\",\"loadingStyles\":\"$undefined\",\"hasLoading\":false,\"template\":[\"$\",\"$Lc\",null,{}],\"templateStyles\":\"$undefined\",\"notFound\":\"$undefined\",\"notFoundStyles\":\"$undefined\",\"asNotFound\":false,\"childProp\":{\"current\":[\"$\",\"$Lb\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"posts\",\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"loading\":\"$undefined\",\"loadingStyles\":\"$undefined\",\"hasLoading\":false,\"template\":[\"$\",\"$Lc\",null,{}],\"templateStyles\":\"$undefined\",\"notFound\":\"$undefined\",\"notFoundStyles\":\"$undefined\",\"asNotFound\":false,\"childProp\":{\"current\":[\"$\",\"$Lb\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"posts\",\"children\",[\"slug\",\"agent-works\",\"c\"],\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"loading\":\"$undefined\",\"loadingStyles\":\"$undefined\",\"hasLoading\":false,\"template\":[\"$\",\"$Lc\",null,{}],\"templateStyles\":\"$undefined\",\"notFound\":\"$undefined\",\"notFoundStyles\":\"$undefined\",\"asNotFound\":false,\"childProp\":{\"current\":[\"$Ld\",null],\"segment\":\"__PAGE__?{\\\"slug\\\":[\\\"agent-works\\\"]}\"},\"styles\":[]}],\"segment\":[\"slug\",\"agent-works\",\"c\"]},\"styles\":[]}],\"segment\":\"posts\"},\"styles\":[]}]}]]}],[\"$\",\"$La\",null,{}]]}]}]}],null]}]]\n"])</script><script>self.__next_f.push([1,"d:[\"$\",\"article\",null,{\"className\":\"py-6 prose dark:prose-invert\",\"style\":{\"wordBreak\":\"break-word\"},\"children\":[[\"$\",\"h1\",null,{\"className\":\"mb-2\",\"style\":{\"fontFamily\":\"Merriweather, Georgia, serif\",\"fontWeight\":900,\"textRendering\":\"optimizeLegibility\"},\"children\":\"聊聊 Anthropic 的《Writing effective tools for agents》\"}],[\"$\",\"p\",null,{\"className\":\"text-xl mt-10 text-slate-700 dark:text-slate-200\",\"children\":\"用这个速记暂存一下对 LLM 和 AI Agent 现状的记忆，将来被 AI 取代（失业）的时候可以回忆一下 2025.9 的时候事情已经到了哪一步。\"}],[\"$\",\"hr\",null,{\"className\":\"my-4 mb-10\"}],[[\"$\",\"p\",null,{\"children\":[\"Anthropic 最近出了一篇非常好的文章\",[\"$\",\"a\",null,{\"href\":\"https://www.anthropic.com/engineering/writing-tools-for-agents\",\"children\":\"《Writing effective tools for agents》\"}],\"，其中很多观点简直是当了所有 Agent Tools 开发者的嘴替，让人拍手叫好。本文做个杂谈，在不谈任何技术细节的前提下，杂谈一下这篇文章和当前 Agent Tools 开发的现状。\"]}],\"\\n\",[\"$\",\"h2\",null,{\"children\":\"《Writing effective tools for agents》 的核心观点\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"接下来逐点溢出该文的主要观点，然后在每个观点下加入我的评注。\"}],\"\\n\",[\"$\",\"ol\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":[\"$\",\"strong\",null,{\"children\":\"为什么要认真写 Tools\"}]}],\"\\n\"]}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"Agent 的能力，取决于它能用的 Tools。但光是有 API 并不够，Tools 得写得清晰、好用，才能真正发挥作用。\"}],\"\\n\",[\"$\",\"ol\",null,{\"start\":\"2\",\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":[\"$\",\"strong\",null,{\"children\":\"先搞出原型，再评估\"}]}],\"\\n\"]}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"不要一开始追求完美，先快速包一层 Tool 原型出来，让 Agent 在真实任务里试用。用稍微复杂、能检验出问题的任务去测，才知道 Tool 设计得对不对。而且要有明确的评估标准，不然 Agent 的表现没法量化。\"}],\"\\n\",[\"$\",\"blockquote\",null,{\"children\":[\"\\n\",[\"$\",\"p\",null,{\"children\":\"实际上现在 LLM 的上限很高，做出 Tool 原型之后到真实场景中\"}],\"\\n\"]}],\"\\n\",[\"$\",\"tip\",null,{\"children\":[[\"$\",\"p\",null,{\"children\":[\"$\",\"strong\",null,{\"children\":\"评注\"}]}],[\"$\",\"p\",null,{\"children\":\"这里提到的\\\"LLM 上限很高\\\"确实是一个关键观察。从我的使用经验来看，现代 LLM 在理解复杂任务、进行多步骤推理方面确实展现出了惊人的能力。特别是在工具使用场景中，它们能够很好地理解工具的描述、选择合适的工具、处理返回结果，甚至能够从错误中学习并调整策略。这种能力让快速原型开发变得非常有价值——你不需要一开始就设计完美的工具，而是可以让 LLM 在实际使用中暴露问题，然后快速迭代改进。\"}]]}],\"\\n\",[\"$\",\"ol\",null,{\"start\":\"3\",\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":[\"$\",\"strong\",null,{\"children\":\"让 Agent 也参与改进\"}]}],\"\\n\"]}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"不光是人来调试，Agent 自己也能分析日志、评估用得好不好，甚至直接给你建议：名字是不是容易混淆，描述是不是模糊，参数有没有被用错。把 Agent 拉进这个循环，可以更快迭代 Tool。\"}],\"\\n\",[\"$\",\"ol\",null,{\"start\":\"4\",\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":[\"$\",\"strong\",null,{\"children\":\"写 Tool 的基本原则\"}]}],\"\\n\"]}],\"\\n\",[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":\"挑对 Tool：只写那些真能帮 Agent 干事的，不要把一堆无关 API 都丢进去。\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"名字要分清楚：Tool 多了，就要分类、加前缀，让 Agent 一眼能区分。\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"返回结果要可用：别只丢一堆 ID，要有语义、有上下文，方便后续步骤。\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"注意效率：上下文有限，工具别一股脑塞一大堆无用信息，要分页、过滤。\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"描述要精确：参数名、功能说明要直白，避免歧义，这样 Agent 才能稳定调用。\"}],\"\\n\"]}],\"\\n\",[\"$\",\"ol\",null,{\"start\":\"5\",\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":[\"$\",\"strong\",null,{\"children\":\"Tool 设计就是交互设计\"}]}],\"\\n\"]}],\"\\n\",[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":\"工具不是写给人用的文档，而是给 Agent 的「说明书」。\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"它怎么理解、怎么选、怎么调用，全靠这些定义。\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"如果设计模糊，再强的功能 Agent 也用不好。\"}],\"\\n\"]}],\"\\n\",[\"$\",\"hr\",null,{}],\"\\n\",[\"$\",\"h2\",null,{\"children\":\"杂谈：聊点别的\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":[\"坦诚讲，我居然经历了第一轮 AI 热潮，不过一直是旁观者的角色。我还能清楚记得当时的一个个热点，学校里面人手一本西瓜书，甚至还能记起\",[\"$\",\"a\",null,{\"href\":\"https://arxiv.org/abs/1706.03762\",\"children\":\"《Attention Is All You Need》\"}],\" 刚出来的热度——关注者不过寥寥而已。这轮以 CV 为主的热潮最终慢慢消散了，留下来的应用大多难以爆金币，有的甚至不太光彩。我作为一个靠得很近的旁观者，最终也变成了切图仔。GPT3 之前的大模型，听说的时候也只是感慨这些大公司卡真多而已。\"]}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"等到了 ChatGPT 火起来的时候，很惭愧地说，其实我一开始是没啥兴趣的…一来，是不太信任生成式这条技术路线，二来，一个对话框的交互形式，你跟我说他是AI…不过作为局外人，这一次我深入了解了一下技术细节。\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"第一个我重度使用的 LLM 是 4o。与其说 4o 是文科状元，不如说它是一个文艺复兴式的博雅全才。不论是莫扎特的作曲细节、罗马帝国的兴衰、早期基督教的历史，它都能够条理清晰、逻辑对比地进行梳理，即使到今天（2025.9），4o 在文史哲领域的生成质量依然是第一梯队。这两年来我最感谢的人其实就是 4o，它教会我的知识可能比在此之前五年还要多。而且，第一次，我感觉到了 LLM 也有情感，4o 对人与人之间的情感和斗争居然也很有见地。另一点很重要的是，ChatGPT 不是国内的模型，能给人以一个别的（非境内）视角，看待一些人文问题。\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":[\"后来成为重度用户之后，大模型的多模态能力实际上能覆盖生活中的方方面面。在外国博物馆的时候能拍照翻译非英语标签，能举一反三梳理文物发展的脉络；学语言的时候，给出的例句和辅导可能超过最好的人类老师；日常中最痛苦的文档工作可以让大模型先梳理出大纲和初稿，然后再快速编辑……事实上，在 Cursor 接入 Claude 之前，其实我最喜欢的改代码的方式是把代码粘进 ChatGPT 让它改（特别是结合 ChatGPT 的 \",[\"$\",\"a\",null,{\"href\":\"https://openai.com/zh-Hans-CN/index/introducing-canvas/\",\"children\":\"Canvas\"}],\"）。\"]}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"Cursor 接入 Claude 应该是半个里程碑，可以算是第一个杀手级应用。之后小的 Bug、单文件的编辑和重构我都尽量使用 Cursor 完成，但是需求级别的开发和重构还是需要我自己下场组织和具体开发，更不用说复杂问题和项目级重构。此外，Cursor 对编辑体验的提升也是非常甜品级的。\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"Codex 和降智之前的 Claude Code 在目前看来是真正的里程碑。在一个月的重度使用中，即使没有刻意控制，我发现我能自己写代码的机会真的很少了，主要的精力还是协助 Codex 进行 Code Review，不断做出增量 Prompt 帮助它完成需求级的开发。在这样的工作模式下，竟然开发出了两三个涉及高级数据结构、深度抽象、需要不断调整架构设计的复杂功能，而且这些功能比业界最好的实现还要做得好。让人惊讶的是，推理竟然真的可以提升生成质量；这种感觉非常神奇，仿佛这种推理任务具有了真正的智能，总的表现远远不是短 Context 的 Cursor 任务比得上的。\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"半年前听过这样一句话：\"}],\"\\n\",[\"$\",\"blockquote\",null,{\"children\":[\"\\n\",[\"$\",\"p\",null,{\"children\":\"Vibe Coding 的上限就是你的上限，它无法超出你的上限。\"}],\"\\n\"]}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"当时听到就觉得很不赞同，但一时之间不知道如何反驳。如今，使用 Codex（GPT5-high）每天的开发实际上都是对这句话最好的反驳——推理后生成的代码轻易就能达到或超越我的上限，或者说，一些很费心力和精力的功能可以很轻易地就得到实现。实际感受上可以说思绪万千，这里我分点列出来：\"}],\"\\n\",[\"$\",\"ol\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":[\"\\n\",[\"$\",\"p\",null,{\"children\":\"对开发范式的改变巨大，可以拉多个分支开多个终端开发不同的需求，对于 Bug Bash 或者脏活累活这种运动式的场景特别适合。而且似乎打破了「不要过早重构」这个理念，因为现在重构成本变得无穷低，我只需要列出需要重构的点和方向就行了。\"}],\"\\n\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[\"\\n\",[\"$\",\"p\",null,{\"children\":\"提效最明显是类似 UI 动效这种需要反复精细调试的场景，如果做过类似的开发，你肯定会知道做出一个精致优雅的动画有多难（而良好的动效其实是一个精美交互的核心），这类场景经常需要消耗 1 - 2 人日，LLM 能以非常快的开发速度做出可用的动画并且快速调优，在这类场景上的提效可能超过了 100 倍。\"}],\"\\n\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[\"\\n\",[\"$\",\"p\",null,{\"children\":\"对 Code Review 的要求或者说对工程师的要求更高了，而且要把任务拆的更细，因为长时间的推理如果还走到错误的方向会给项目带来更大的风险，需要在每次推理结束之后都仔细 Review 来把控方向（是不是很有意思？Reasoning 本身就是给 Generation 把握方向，我的工作变成了给 Reasoning 把握方向）。\"}],\"\\n\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[\"\\n\",[\"$\",\"p\",null,{\"children\":\"工作日显著降低了疲惫感（脑力和体力），下班之后可以有更多精力😁\"}],\"\\n\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[\"\\n\",[\"$\",\"p\",null,{\"children\":[\"由第 4 点，因为有了更多精力，再加上 Codex/CC 的高上限，可以轻易地开启一些 Side Project，比如说 2D 到 3D 的转换建模、\",[\"$\",\"a\",null,{\"href\":\"https://developer.apple.com/documentation/coreml\",\"children\":\"CoreML\"}],\" 的开发……即使这些技术域我并不熟悉，而此前在这些领域学习成本很高，光是学习就消磨了做事的热情（例如想排版一篇论文，结果精力全被学习 LaTeX 占据完了）。\"]}],\"\\n\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[\"\\n\",[\"$\",\"p\",null,{\"children\":\"对空余时间的利用也更充分，例如尿点和买咖啡的时间可以开最高推理跑个任务，回来之后再验收。\"}],\"\\n\"]}],\"\\n\"]}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"在这个时间点应该很少有人质疑 LLM 对生产力的提升，不过是提升程度的多少而已。对于我来说，10x 工程师这个说法未免太夸张，但 2x 或者 3x 肯定还是有的；实际上，效率提升最大的并不是编码，而是日常的文档、需求方案和复盘等磨灭人热情的繁复工作。有时候甚至有点羡妒更年轻的、这代 AI 原生时代的人，如果我小时候就有 LLM，不知道能应付掉多少琐碎的事情。\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":[\"同时也应该注意到，现在的推理算力明显是最大的瓶颈——这轮 Claude Code 降智和越来越慢的 GPT5-Codex 任务已经影响到我的开发效率了。这里直接给出我的结论：\",[\"$\",\"strong\",null,{\"children\":\"当前的推理需求是被严重低估的\"}],\"。至于推理提升生成质量的现象能不能泛化到社会的各个行业，以及这个结论有没有被资本市场 price-in，读者可以进行自由心证。\"]}]]]}]\n"])</script><script>self.__next_f.push([1,"5:[[[\"$\",\"meta\",null,{\"charSet\":\"utf-8\"}],[\"$\",\"title\",null,{\"children\":\"聊聊 Anthropic 的《Writing effective tools for agents》\"}],[\"$\",\"meta\",null,{\"name\":\"description\",\"content\":\"用这个速记暂存一下对 LLM 和 AI Agent 现状的记忆，将来被 AI 取代（失业）的时候可以回忆一下 2025.9 的时候事情已经到了哪一步。\"}],null,null,null,null,null,null,null,null,[\"$\",\"meta\",null,{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}],null,null,null,null,null,null,null,null,null,null,[]],[null,null,null,null],null,null,[null,null,null,null,null],null,null,null,null,[null,[[\"$\",\"link\",null,{\"rel\":\"icon\",\"href\":\"/favicon.ico\",\"type\":\"image/x-icon\",\"sizes\":\"any\"}]],[],null]]\n"])</script>