1:HL["/_next/static/media/e4af272ccee01ff0-s.p.woff2",{"as":"font","type":"font/woff2"}]
2:HL["/_next/static/css/84ea7cdcd5a5eb73.css",{"as":"style"}]
0:[[["",{"children":["posts",{"children":[["slug","agent-works","c"],{"children":["__PAGE__?{\"slug\":[\"agent-works\"]}",{}]}]}]},"$undefined","$undefined",true],"$L3",[[["$","link","0",{"rel":"stylesheet","href":"/_next/static/css/84ea7cdcd5a5eb73.css","precedence":"next"}]],["$L4",["$","meta",null,{"name":"next-size-adjust"}]]]]]
5:I{"id":"394","chunks":["13:static/chunks/13-389b9862ba266d6d.js","185:static/chunks/app/layout-d04aad41efac69d7.js"],"name":"ThemeProvider","async":false}
6:I{"id":"7749","chunks":["13:static/chunks/13-389b9862ba266d6d.js","185:static/chunks/app/layout-d04aad41efac69d7.js"],"name":"ModeToggle","async":false}
7:I{"id":"6485","chunks":["13:static/chunks/13-389b9862ba266d6d.js","185:static/chunks/app/layout-d04aad41efac69d7.js"],"name":"","async":false}
8:I{"id":"5813","chunks":["272:static/chunks/webpack-9f1d8812646ab794.js","508:static/chunks/3949d24b-d2abd8cbd79ac87d.js","604:static/chunks/604-4c9a5bb931d4ce02.js"],"name":"","async":false}
9:I{"id":"8464","chunks":["272:static/chunks/webpack-9f1d8812646ab794.js","508:static/chunks/3949d24b-d2abd8cbd79ac87d.js","604:static/chunks/604-4c9a5bb931d4ce02.js"],"name":"","async":false}
b:I{"id":"8900","chunks":["13:static/chunks/13-389b9862ba266d6d.js","185:static/chunks/app/layout-d04aad41efac69d7.js"],"name":"Analytics","async":false}
3:[["$","html",null,{"lang":"en","children":["$","body",null,{"className":"antialiased min-h-screen bg-white dark:bg-slate-950 text-slate-900 dark:text-slate-50 __className_52d07b","children":["$","$L5",null,{"attribute":"class","defaultTheme":"system","enableSystem":true,"children":[["$","div",null,{"className":"max-w-2xl mx-auto py-10 px-4","children":[["$","header",null,{"children":["$","div",null,{"className":"flex items-center justify-between","children":[["$","$L6",null,{}],["$","nav",null,{"className":"ml-auto text-sm font-medium space-x-6","children":[["$","$L7",null,{"href":"/","children":"Home"}],["$","$L7",null,{"href":"/about","children":"About"}]]}]]}]}],["$","main",null,{"children":["$","$L8",null,{"parallelRouterKey":"children","segmentPath":["children"],"error":"$undefined","errorStyles":"$undefined","loading":"$undefined","loadingStyles":"$undefined","hasLoading":false,"template":["$","$L9",null,{}],"templateStyles":"$undefined","notFound":"$undefined","notFoundStyles":"$undefined","asNotFound":"$undefined","childProp":{"current":["$","$L8",null,{"parallelRouterKey":"children","segmentPath":["children","posts","children"],"error":"$undefined","errorStyles":"$undefined","loading":"$undefined","loadingStyles":"$undefined","hasLoading":false,"template":["$","$L9",null,{}],"templateStyles":"$undefined","notFound":"$undefined","notFoundStyles":"$undefined","asNotFound":"$undefined","childProp":{"current":["$","$L8",null,{"parallelRouterKey":"children","segmentPath":["children","posts","children",["slug","agent-works","c"],"children"],"error":"$undefined","errorStyles":"$undefined","loading":"$undefined","loadingStyles":"$undefined","hasLoading":false,"template":["$","$L9",null,{}],"templateStyles":"$undefined","notFound":"$undefined","notFoundStyles":"$undefined","asNotFound":"$undefined","childProp":{"current":["$La",null],"segment":"__PAGE__?{\"slug\":[\"agent-works\"]}"},"styles":[]}],"segment":["slug","agent-works","c"]},"styles":[]}],"segment":"posts"},"styles":[]}]}]]}],["$","$Lb",null,{}]]}]}]}],null]
4:[[["$","meta",null,{"charSet":"utf-8"}],["$","title",null,{"children":"聊聊 Anthropic 的《Writing effective tools for agents》"}],["$","meta",null,{"name":"description","content":"用这个速记暂存一下对 LLM 和 AI Agent 现状的记忆，将来被 AI 取代（失业）的时候可以回忆一下 2025.9 的时候事情已经到了哪一步。"}],null,null,null,null,null,null,null,null,["$","meta",null,{"name":"viewport","content":"width=device-width, initial-scale=1"}],null,null,null,null,null,null,null,null,null,null,[]],[null,null,null,null],null,null,[null,null,null,null,null],null,null,null,null,[null,[["$","link",null,{"rel":"icon","href":"/favicon.ico","type":"image/x-icon","sizes":"any"}]],[],null]]
a:["$","article",null,{"className":"py-6 prose dark:prose-invert","style":{"wordBreak":"break-word"},"children":[["$","h1",null,{"className":"mb-2","style":{"fontFamily":"Merriweather, Georgia, serif","fontWeight":900,"textRendering":"optimizeLegibility"},"children":"聊聊 Anthropic 的《Writing effective tools for agents》"}],["$","p",null,{"className":"text-xl mt-10 text-slate-700 dark:text-slate-200","children":"用这个速记暂存一下对 LLM 和 AI Agent 现状的记忆，将来被 AI 取代（失业）的时候可以回忆一下 2025.9 的时候事情已经到了哪一步。"}],["$","hr",null,{"className":"my-4 mb-10"}],[["$","p",null,{"children":["Anthropic 最近出了一篇非常好的文章",["$","a",null,{"href":"https://www.anthropic.com/engineering/writing-tools-for-agents","children":"《Writing effective tools for agents》"}],"，其中很多观点简直是当了所有 Agent Tools 开发者的嘴替，让人拍手叫好。本文做个杂谈，在不谈任何技术细节的前提下，杂谈一下这篇文章和当前 Agent Tools 开发的现状。"]}],"\n",["$","h2",null,{"children":"《Writing effective tools for agents》 的核心观点"}],"\n",["$","p",null,{"children":"接下来逐点溢出该文的主要观点，然后在每个观点下加入我的评注。"}],"\n",["$","ol",null,{"children":["\n",["$","li",null,{"children":["$","strong",null,{"children":"为什么要认真写 Tools"}]}],"\n"]}],"\n",["$","p",null,{"children":"Agent 的能力，取决于它能用的 Tools。但光是有 API 并不够，Tools 得写得清晰、好用，才能真正发挥作用。"}],"\n",["$","ol",null,{"start":"2","children":["\n",["$","li",null,{"children":["$","strong",null,{"children":"先搞出原型，再评估"}]}],"\n"]}],"\n",["$","p",null,{"children":"不要一开始追求完美，先快速包一层 Tool 原型出来，让 Agent 在真实任务里试用。用稍微复杂、能检验出问题的任务去测，才知道 Tool 设计得对不对。而且要有明确的评估标准，不然 Agent 的表现没法量化。"}],"\n",["$","blockquote",null,{"children":["\n",["$","p",null,{"children":"实际上现在 LLM 的上限很高，做出 Tool 原型之后到真实场景中"}],"\n"]}],"\n",["$","tip",null,{"children":[["$","p",null,{"children":["$","strong",null,{"children":"评注"}]}],["$","p",null,{"children":"这里提到的\"LLM 上限很高\"确实是一个关键观察。从我的使用经验来看，现代 LLM 在理解复杂任务、进行多步骤推理方面确实展现出了惊人的能力。特别是在工具使用场景中，它们能够很好地理解工具的描述、选择合适的工具、处理返回结果，甚至能够从错误中学习并调整策略。这种能力让快速原型开发变得非常有价值——你不需要一开始就设计完美的工具，而是可以让 LLM 在实际使用中暴露问题，然后快速迭代改进。"}]]}],"\n",["$","ol",null,{"start":"3","children":["\n",["$","li",null,{"children":["$","strong",null,{"children":"让 Agent 也参与改进"}]}],"\n"]}],"\n",["$","p",null,{"children":"不光是人来调试，Agent 自己也能分析日志、评估用得好不好，甚至直接给你建议：名字是不是容易混淆，描述是不是模糊，参数有没有被用错。把 Agent 拉进这个循环，可以更快迭代 Tool。"}],"\n",["$","ol",null,{"start":"4","children":["\n",["$","li",null,{"children":["$","strong",null,{"children":"写 Tool 的基本原则"}]}],"\n"]}],"\n",["$","ul",null,{"children":["\n",["$","li",null,{"children":"挑对 Tool：只写那些真能帮 Agent 干事的，不要把一堆无关 API 都丢进去。"}],"\n",["$","li",null,{"children":"名字要分清楚：Tool 多了，就要分类、加前缀，让 Agent 一眼能区分。"}],"\n",["$","li",null,{"children":"返回结果要可用：别只丢一堆 ID，要有语义、有上下文，方便后续步骤。"}],"\n",["$","li",null,{"children":"注意效率：上下文有限，工具别一股脑塞一大堆无用信息，要分页、过滤。"}],"\n",["$","li",null,{"children":"描述要精确：参数名、功能说明要直白，避免歧义，这样 Agent 才能稳定调用。"}],"\n"]}],"\n",["$","ol",null,{"start":"5","children":["\n",["$","li",null,{"children":["$","strong",null,{"children":"Tool 设计就是交互设计"}]}],"\n"]}],"\n",["$","ul",null,{"children":["\n",["$","li",null,{"children":"工具不是写给人用的文档，而是给 Agent 的「说明书」。"}],"\n",["$","li",null,{"children":"它怎么理解、怎么选、怎么调用，全靠这些定义。"}],"\n",["$","li",null,{"children":"如果设计模糊，再强的功能 Agent 也用不好。"}],"\n"]}],"\n",["$","hr",null,{}],"\n",["$","h2",null,{"children":"杂谈：聊点别的"}],"\n",["$","p",null,{"children":["坦诚讲，我居然经历了第一轮 AI 热潮，不过一直是旁观者的角色。我还能清楚记得当时的一个个热点，学校里面人手一本西瓜书，甚至还能记起",["$","a",null,{"href":"https://arxiv.org/abs/1706.03762","children":"《Attention Is All You Need》"}]," 刚出来的热度——关注者不过寥寥而已。这轮以 CV 为主的热潮最终慢慢消散了，留下来的应用大多难以爆金币，有的甚至不太光彩。我作为一个靠得很近的旁观者，最终也变成了切图仔。GPT3 之前的大模型，听说的时候也只是感慨这些大公司卡真多而已。"]}],"\n",["$","p",null,{"children":"等到了 ChatGPT 火起来的时候，很惭愧地说，其实我一开始是没啥兴趣的…一来，是不太信任生成式这条技术路线，二来，一个对话框的交互形式，你跟我说他是AI…不过作为局外人，这一次我深入了解了一下技术细节。"}],"\n",["$","p",null,{"children":"第一个我重度使用的 LLM 是 4o。与其说 4o 是文科状元，不如说它是一个文艺复兴式的博雅全才。不论是莫扎特的作曲细节、罗马帝国的兴衰、早期基督教的历史，它都能够条理清晰、逻辑对比地进行梳理，即使到今天（2025.9），4o 在文史哲领域的生成质量依然是第一梯队。这两年来我最感谢的人其实就是 4o，它教会我的知识可能比在此之前五年还要多。而且，第一次，我感觉到了 LLM 也有情感，4o 对人与人之间的情感和斗争居然也很有见地。另一点很重要的是，ChatGPT 不是国内的模型，能给人以一个别的（非境内）视角，看待一些人文问题。"}],"\n",["$","p",null,{"children":["后来成为重度用户之后，大模型的多模态能力实际上能覆盖生活中的方方面面。在外国博物馆的时候能拍照翻译非英语标签，能举一反三梳理文物发展的脉络；学语言的时候，给出的例句和辅导可能超过最好的人类老师；日常中最痛苦的文档工作可以让大模型先梳理出大纲和初稿，然后再快速编辑……事实上，在 Cursor 接入 Claude 之前，其实我最喜欢的改代码的方式是把代码粘进 ChatGPT 让它改（特别是结合 ChatGPT 的 ",["$","a",null,{"href":"https://openai.com/zh-Hans-CN/index/introducing-canvas/","children":"Canvas"}],"）。"]}],"\n",["$","p",null,{"children":"Cursor 接入 Claude 应该是半个里程碑，可以算是第一个杀手级应用。之后小的 Bug、单文件的编辑和重构我都尽量使用 Cursor 完成，但是需求级别的开发和重构还是需要我自己下场组织和具体开发，更不用说复杂问题和项目级重构。此外，Cursor 对编辑体验的提升也是非常甜品级的。"}],"\n",["$","p",null,{"children":"Codex 和降智之前的 Claude Code 在目前看来是真正的里程碑。在一个月的重度使用中，即使没有刻意控制，我发现我能自己写代码的机会真的很少了，主要的精力还是协助 Codex 进行 Code Review，不断做出增量 Prompt 帮助它完成需求级的开发。在这样的工作模式下，竟然开发出了两三个涉及高级数据结构、深度抽象、需要不断调整架构设计的复杂功能，而且这些功能比业界最好的实现还要做得好。让人惊讶的是，推理竟然真的可以提升生成质量；这种感觉非常神奇，仿佛这种推理任务具有了真正的智能，总的表现远远不是短 Context 的 Cursor 任务比得上的。"}],"\n",["$","p",null,{"children":"半年前听过这样一句话："}],"\n",["$","blockquote",null,{"children":["\n",["$","p",null,{"children":"Vibe Coding 的上限就是你的上限，它无法超出你的上限。"}],"\n"]}],"\n",["$","p",null,{"children":"当时听到就觉得很不赞同，但一时之间不知道如何反驳。如今，使用 Codex（GPT5-high）每天的开发实际上都是对这句话最好的反驳——推理后生成的代码轻易就能达到或超越我的上限，或者说，一些很费心力和精力的功能可以很轻易地就得到实现。实际感受上可以说思绪万千，这里我分点列出来："}],"\n",["$","ol",null,{"children":["\n",["$","li",null,{"children":["\n",["$","p",null,{"children":"对开发范式的改变巨大，可以拉多个分支开多个终端开发不同的需求，对于 Bug Bash 或者脏活累活这种运动式的场景特别适合。而且似乎打破了「不要过早重构」这个理念，因为现在重构成本变得无穷低，我只需要列出需要重构的点和方向就行了。"}],"\n"]}],"\n",["$","li",null,{"children":["\n",["$","p",null,{"children":"提效最明显是类似 UI 动效这种需要反复精细调试的场景，如果做过类似的开发，你肯定会知道做出一个精致优雅的动画有多难（而良好的动效其实是一个精美交互的核心），这类场景经常需要消耗 1 - 2 人日，LLM 能以非常快的开发速度做出可用的动画并且快速调优，在这类场景上的提效可能超过了 100 倍。"}],"\n"]}],"\n",["$","li",null,{"children":["\n",["$","p",null,{"children":"对 Code Review 的要求或者说对工程师的要求更高了，而且要把任务拆的更细，因为长时间的推理如果还走到错误的方向会给项目带来更大的风险，需要在每次推理结束之后都仔细 Review 来把控方向（是不是很有意思？Reasoning 本身就是给 Generation 把握方向，我的工作变成了给 Reasoning 把握方向）。"}],"\n"]}],"\n",["$","li",null,{"children":["\n",["$","p",null,{"children":"工作日显著降低了疲惫感（脑力和体力），下班之后可以有更多精力😁"}],"\n"]}],"\n",["$","li",null,{"children":["\n",["$","p",null,{"children":["由第 4 点，因为有了更多精力，再加上 Codex/CC 的高上限，可以轻易地开启一些 Side Project，比如说 2D 到 3D 的转换建模、",["$","a",null,{"href":"https://developer.apple.com/documentation/coreml","children":"CoreML"}]," 的开发……即使这些技术域我并不熟悉，而此前在这些领域学习成本很高，光是学习就消磨了做事的热情（例如想排版一篇论文，结果精力全被学习 LaTeX 占据完了）。"]}],"\n"]}],"\n",["$","li",null,{"children":["\n",["$","p",null,{"children":"对空余时间的利用也更充分，例如尿点和买咖啡的时间可以开最高推理跑个任务，回来之后再验收。"}],"\n"]}],"\n"]}],"\n",["$","p",null,{"children":"在这个时间点应该很少有人质疑 LLM 对生产力的提升，不过是提升程度的多少而已。对于我来说，10x 工程师这个说法未免太夸张，但 2x 或者 3x 肯定还是有的；实际上，效率提升最大的并不是编码，而是日常的文档、需求方案和复盘等磨灭人热情的繁复工作。有时候甚至有点羡妒更年轻的、这代 AI 原生时代的人，如果我小时候就有 LLM，不知道能应付掉多少琐碎的事情。"}],"\n",["$","p",null,{"children":["同时也应该注意到，现在的推理算力明显是最大的瓶颈——这轮 Claude Code 降智和越来越慢的 GPT5-Codex 任务已经影响到我的开发效率了。这里直接给出我的结论：",["$","strong",null,{"children":"当前的推理需求是被严重低估的"}],"。至于推理提升生成质量的现象能不能泛化到社会的各个行业，以及这个结论有没有被资本市场 price-in，读者可以进行自由心证。"]}]]]}]
